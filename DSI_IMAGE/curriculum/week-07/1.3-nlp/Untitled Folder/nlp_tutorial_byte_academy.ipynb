{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-07T18:49:10.587498",
     "start_time": "2016-11-07T18:49:07.610408"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def format_sentence(sent):\n",
    "    return {word: True for word in nltk.word_tokenize(sent)}\n",
    "    \n",
    "pos = []\n",
    "with open(\"./pos.txt\") as f:\n",
    "    for i in f: \n",
    "        pos.append([format_sentence(i.decode('utf-8')), 'pos'])\n",
    "        \n",
    "neg = []\n",
    "with open(\"./neg.txt\") as f:\n",
    "    for i in f: \n",
    "        neg.append([format_sentence(i.decode('utf-8')), 'neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-07T18:49:31.281768",
     "start_time": "2016-11-07T18:49:31.276155"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = pos[:int((.9)*len(pos))] + neg[:int((.9)*len(neg))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-07T18:49:56.873056",
     "start_time": "2016-11-07T18:49:56.867340"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pos[int((.1)*len(pos)):] + neg[int((.1)*len(neg)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-07T18:50:18.303974",
     "start_time": "2016-11-07T18:50:17.934807"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-07T18:51:16.648270",
     "start_time": "2016-11-07T18:51:16.421706"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                      no = True              neg : pos    =     20.6 : 1.0\n",
      "                 awesome = True              pos : neg    =     18.7 : 1.0\n",
      "                headache = True              neg : pos    =     18.0 : 1.0\n",
      "               beautiful = True              pos : neg    =     14.2 : 1.0\n",
      "                    love = True              pos : neg    =     14.2 : 1.0\n",
      "                      Hi = True              pos : neg    =     12.7 : 1.0\n",
      "                    glad = True              pos : neg    =      9.7 : 1.0\n",
      "                   Thank = True              pos : neg    =      9.7 : 1.0\n",
      "                     fan = True              pos : neg    =      9.7 : 1.0\n",
      "                    lost = True              neg : pos    =      9.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-07T18:52:58.481453",
     "start_time": "2016-11-07T18:52:58.474023"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n"
     ]
    }
   ],
   "source": [
    "example1 = \"this workshop is awesome.\"\n",
    "\n",
    "print classifier.classify(format_sentence(example1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-07T18:53:08.404762",
     "start_time": "2016-11-07T18:53:08.398427"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n"
     ]
    }
   ],
   "source": [
    "example1 = \"this workshop is aweful.\"\n",
    "\n",
    "print classifier.classify(format_sentence(example1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-07T18:55:11.177143",
     "start_time": "2016-11-07T18:55:10.821118"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956232686981\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.util import accuracy\n",
    "print accuracy(classifier, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-07T19:06:08.486010",
     "start_time": "2016-11-07T19:06:07.918421"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('an', 'DT'),\n",
       " ('awesome', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('!', '.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "\n",
    "text = nltk.word_tokenize(\"Python is an awesome language!\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-07T19:06:24.584957",
     "start_time": "2016-11-07T19:06:24.568545"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('JJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-07T19:07:01.844419",
     "start_time": "2016-11-07T19:06:59.657548"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Various', u'JJ'),\n",
       " (u'of', u'IN'),\n",
       " (u'the', u'AT'),\n",
       " (u'apartments', u'NNS'),\n",
       " (u'are', u'BER'),\n",
       " (u'of', u'IN'),\n",
       " (u'the', u'AT'),\n",
       " (u'terrace', u'NN'),\n",
       " (u'type', u'NN'),\n",
       " (u',', u','),\n",
       " (u'being', u'BEG'),\n",
       " (u'on', u'IN'),\n",
       " (u'the', u'AT'),\n",
       " (u'ground', u'NN'),\n",
       " (u'floor', u'NN'),\n",
       " (u'so', u'QL'),\n",
       " (u'that', u'CS'),\n",
       " (u'entrance', u'NN'),\n",
       " (u'is', u'BEZ'),\n",
       " (u'direct', u'JJ'),\n",
       " (u'.', u'.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "brown_sents = brown.sents(categories='news')\n",
    "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)\n",
    "unigram_tagger.tag(brown_sents[2007])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-07T19:08:30.999719",
     "start_time": "2016-11-07T19:08:29.105899"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Various', u'JJ'),\n",
       " (u'of', u'IN'),\n",
       " (u'the', u'AT'),\n",
       " (u'apartments', u'NNS'),\n",
       " (u'are', u'BER'),\n",
       " (u'of', u'IN'),\n",
       " (u'the', u'AT'),\n",
       " (u'terrace', u'NN'),\n",
       " (u'type', u'NN'),\n",
       " (u',', u','),\n",
       " (u'being', u'BEG'),\n",
       " (u'on', u'IN'),\n",
       " (u'the', u'AT'),\n",
       " (u'ground', u'NN'),\n",
       " (u'floor', u'NN'),\n",
       " (u'so', u'CS'),\n",
       " (u'that', u'CS'),\n",
       " (u'entrance', u'NN'),\n",
       " (u'is', u'BEZ'),\n",
       " (u'direct', u'JJ'),\n",
       " (u'.', u'.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tagger = nltk.BigramTagger(brown_tagged_sents)\n",
    "bigram_tagger.tag(brown_sents[2007])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-07T19:08:44.512796",
     "start_time": "2016-11-07T19:08:44.506387"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw = \"OMG, Natural Language Processing is SO cool and I'm really enjoying this workshop!\"\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "tokens = [i.lower() for i in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-07T19:09:39.209509",
     "start_time": "2016-11-07T19:09:39.199506"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['omg',\n",
       " ',',\n",
       " 'nat',\n",
       " 'langu',\n",
       " 'process',\n",
       " 'is',\n",
       " 'so',\n",
       " 'cool',\n",
       " 'and',\n",
       " 'i',\n",
       " \"'m\",\n",
       " 'real',\n",
       " 'enjoy',\n",
       " 'thi',\n",
       " 'workshop',\n",
       " '!']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lancaster = nltk.LancasterStemmer()\n",
    "stems = [lancaster.stem(i) for i in tokens]\n",
    "stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-07T19:10:04.880762",
     "start_time": "2016-11-07T19:10:04.871556"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'omg',\n",
       " u',',\n",
       " u'natur',\n",
       " u'languag',\n",
       " u'process',\n",
       " u'is',\n",
       " u'so',\n",
       " u'cool',\n",
       " u'and',\n",
       " u'i',\n",
       " u\"'m\",\n",
       " u'realli',\n",
       " u'enjoy',\n",
       " u'thi',\n",
       " u'workshop',\n",
       " u'!']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "stem = [porter.stem(i) for i in tokens]\n",
    "stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-07T19:10:58.458534",
     "start_time": "2016-11-07T19:10:58.447050"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'woman', 'in', 'technology', 'are', 'amazing', 'at', 'coding']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "lemma = nltk.WordNetLemmatizer()\n",
    "text = \"Women in technology are amazing at coding\"\n",
    "ex = [i.lower() for i in text.split()]\n",
    "\n",
    "lemmas = [lemma.lemmatize(i) for i in ex]\n",
    "lemmas"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
