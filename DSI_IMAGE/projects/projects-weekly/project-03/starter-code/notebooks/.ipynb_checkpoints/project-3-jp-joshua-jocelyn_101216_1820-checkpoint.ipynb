{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "Once you've chosen your scenario, download the data from [the Iowa website](https://data.iowa.gov/Economy/Iowa-Liquor-Sales/m3tr-qhgy) in csv format. Start by loading the data with pandas. You may need to parse the date columns appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:32.958434",
     "start_time": "2016-10-12T18:21:30.260390"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:32.966854",
     "start_time": "2016-10-12T18:21:32.961128"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Format how pandas returns floats\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:32.980349",
     "start_time": "2016-10-12T18:21:32.970351"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We decided to bring in external data so we'll be reading from three files\n",
    "# Write a function that loads the data and returns a dataframe\n",
    "def load_file(file_name):\n",
    "    file_path_name = base_path + file_name\n",
    "    try:\n",
    "        return pd.read_csv(file_path_name, low_memory=False)\n",
    "    except:\n",
    "        print 'Error: Check file path/ name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:32.990777",
     "start_time": "2016-10-12T18:21:32.984162"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define our base path\n",
    "base_path = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.004163",
     "start_time": "2016-10-12T18:21:32.993464"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Check file path/ name\n"
     ]
    }
   ],
   "source": [
    "## Load the liquor sales data into a DataFrame\n",
    "df = load_file('Iowa_Liquor_sales_sample_10pct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.467122",
     "start_time": "2016-10-12T18:21:33.009959"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2bf1a39b6075>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Transform the dates if needed, e.g.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%m/%d/%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "## Transform the dates if needed, e.g.\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.467873",
     "start_time": "2016-10-12T22:21:30.300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To facilitate using a bigger file later, we'll keep just the columns that are available in this dataset\n",
    "all_columns = df.columns.values.tolist()\n",
    "df = df.copy()[all_columns]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure accuracy, we are importing a list of Iowa zip codes, cities, counties and county numbers for the purposes of cleaning our data. We obtained our data from [here](http://www.unitedstateszipcodes.org/zip-code-database/), [here](http://www.iowayouthsurvey.iowa.gov/images/iacountiesnumbers.pdf) and [here](https://www.census.gov/geo/maps-data/data/tiger-line.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.468438",
     "start_time": "2016-10-12T22:21:30.349Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in our location data file\n",
    "location_data = load_file('ia_zip_city_county_sqkm.csv')\n",
    "location_data = location_data.drop(location_data.columns[0], axis=1)\n",
    "location_data['Zip Code'] = location_data['Zip Code'].astype(str)\n",
    "location_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our hypothesis is that the demographics of an area affects the liquor sales. To test this, we brought in demographic data from [here](http://www.iowadatacenter.org/browse/ZCTAs.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.469015",
     "start_time": "2016-10-12T22:21:30.398Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in our demographic data file\n",
    "demo_data = load_file('IowaZIPdemos.csv')\n",
    "\n",
    "# Remove any rows with null values\n",
    "demo_data.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.470038",
     "start_time": "2016-10-12T22:21:30.409Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All our data should be integers or floats\n",
    "# Create a list of column names if those columns are objects\n",
    "demo_cols = demo_data.columns.values.tolist()\n",
    "object_cols = [i for i in demo_cols if demo_data[i].dtype == 'O']\n",
    "\n",
    "# Define a function to remove symbols and convert numbers to floats\n",
    "def rem_symbols(x):\n",
    "    for i in [',', '%', '$', '-']:\n",
    "        x = x.replace(i, '')\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        print x\n",
    "\n",
    "# Convert all columns to floats\n",
    "for i in object_cols:\n",
    "    demo_data[i] = demo_data[i].map(rem_symbols)\n",
    "\n",
    "# Convert zips to strings for easy comparison\n",
    "demo_data['Area'] = demo_data['Area'].astype(str)\n",
    "demo_data['Area'] = demo_data['Area'].map(lambda x: x.strip('.0'))\n",
    "demo_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run a check on zip codes before joining the liquor sales data and the location data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.471220",
     "start_time": "2016-10-12T22:21:30.464Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a list of unique zip codes in the liquor sales data\n",
    "liquor_zips = df['Zip Code'].drop_duplicates().tolist()\n",
    "\n",
    "# Create a list of unique zip codes as strings from the location data\n",
    "ref_zips = location_data['Zip Code'].tolist()\n",
    "\n",
    "# Create a list of zip codes that are present in the liquor sales data but not in the location data\n",
    "not_found = [x for x in liquor_zips if x not in ref_zips]\n",
    "print not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.471851",
     "start_time": "2016-10-12T22:21:30.468Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For each 'unknown' zip code, we obtain the corresponding city, county and county number in the liquor sales data\n",
    "# and return the same data for that city in our location data\n",
    "for i in not_found:\n",
    "    print df[['Zip Code', 'City', 'County', 'County Number']][df['Zip Code'] == i].drop_duplicates()\n",
    "    city = df['City'][df['Zip Code'] == i].drop_duplicates().iloc[0].upper()\n",
    "    print city\n",
    "    try:\n",
    "        print location_data[location_data['City']==city].drop_duplicates()\n",
    "    except:\n",
    "        print i, 'not in Iowa'\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above, we can kind of see what these zip codes are supposed to be.  \n",
    "Note: We will only be able to do this for a small dataset. As the dataset gets larger, more 'unknown' zips may appear and we may not be able to clean this manually.  \n",
    "\n",
    "Also note that the zip for Delaware, Delaware, Iowa is in fact correct. However, as it had a small population of 159 as at the 2010 census, we will not be considering it for the purposes of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.472324",
     "start_time": "2016-10-12T22:21:30.492Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to map the correct zip codes to the incorrect ones\n",
    "# We will change 52036 to 0 so as to ignore it later on\n",
    "corrected_zips = {'52303': '52403',\\\n",
    "                  '712-2': '51529',\\\n",
    "                  '52087': '52057',\\\n",
    "                  '52084': '52804',\\\n",
    "                  '52036': '0',\\\n",
    "                  '52733': '52732',\\\n",
    "                  '56201': '52601',\\\n",
    "                  '50300': '50309'}\n",
    "\n",
    "for i in range(len(not_found)):\n",
    "    df.ix[df['Zip Code']==corrected_zips.keys()[i], 'Zip Code']=corrected_zips.values()[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.472821",
     "start_time": "2016-10-12T22:21:30.500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a new dataframe to take the merged data\n",
    "df2 = df.copy()\n",
    "df2.drop(['County Number', 'City', 'County'], axis=1, inplace=True)\n",
    "df2 = df2.merge(location_data, how='left', on='Zip Code')\n",
    "df2.drop(['State'], axis=1, inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.473351",
     "start_time": "2016-10-12T22:21:30.504Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write a function that cross references related columns and fills the data in where it's missing\n",
    "def fill_missing(related_cols, column, dataframe):\n",
    "    related_cols.remove(column)\n",
    "    reference = dataframe[related_cols][dataframe[column].isnull()].drop_duplicates()\n",
    "    for j in range(len(related_cols)):\n",
    "        col_1 = reference[related_cols[j]]\n",
    "        for i in col_1:\n",
    "            try:\n",
    "                x = dataframe[column][(dataframe[related_cols[j]]==i) & (dataframe[column].notnull())].drop_duplicates()\n",
    "                if len(x) < 2:\n",
    "                    value = x.iloc[0]\n",
    "                    dataframe.ix[(dataframe[related_cols[j]]==i) & (dataframe[column].isnull()), column] = value\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.473778",
     "start_time": "2016-10-12T22:21:30.508Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run our function to cross check category numbers and names\n",
    "fill_missing(['Category', 'Category Name'], 'Category Name', df2)\n",
    "fill_missing(['Category', 'Category Name'], 'Category', df2)\n",
    "\n",
    "# Run our function to cross check item numbers and names\n",
    "fill_missing(['Item Number', 'Item Description'], 'Item Description', df2)\n",
    "fill_missing(['Item Number', 'Item Description'], 'Item Number', df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.474209",
     "start_time": "2016-10-12T22:21:30.511Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert all dollar columns to floats\n",
    "df2['State Bottle Cost'] = df2['State Bottle Cost'].map(lambda x: x.strip('$')).astype(float)\n",
    "df2['State Bottle Retail'] = df2['State Bottle Retail'].map(lambda x: x.strip('$')).astype(float)\n",
    "df2['Sale (Dollars)'] = df2['Sale (Dollars)'].map(lambda x: x.strip('$')).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T08:03:45.954603",
     "start_time": "2016-10-12T08:03:45.947919"
    }
   },
   "source": [
    "\n",
    "# Explore the data\n",
    "\n",
    "Perform some exploratory statistical analysis and make some plots, such as histograms of transaction totals, bottles sold, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.474629",
     "start_time": "2016-10-12T22:21:30.546Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract Month and Year\n",
    "df2['Month'] = df2['Date'].map(lambda x: x.month)\n",
    "df2['Year'] = df2['Date'].map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.475047",
     "start_time": "2016-10-12T22:21:30.552Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For the purposes of market research, we would want to look at full year data\n",
    "# Find all the non full years in the data set\n",
    "not_full_years = [i for i in df2['Year'].unique() if len(df2['Month'][df2['Year']==i].unique()) != 12]\n",
    "not_full_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.475460",
     "start_time": "2016-10-12T22:21:30.555Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in not_full_years:\n",
    "    df2 = df2.drop(df2[df2['Year']==i].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.475869",
     "start_time": "2016-10-12T22:21:30.559Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.476282",
     "start_time": "2016-10-12T22:21:30.564Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the distribution of 'Bottles Sold', 'Sale (Dollars)', and 'Volume Sold (Liters)'\n",
    "# aggregated by store number\n",
    "hist_cols = ['Bottles Sold', 'Sale (Dollars)', 'Volume Sold (Liters)']\n",
    "for i in hist_cols:\n",
    "    sns.distplot(df2.groupby('Store Number')[i].sum());\n",
    "    plt.title(i);\n",
    "    plt.xlabel(i);\n",
    "    plt.ylabel('Frequency');\n",
    "    plt.xticks(rotation=45);\n",
    "    plt.show();\n",
    "    print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are outliers in all cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.476691",
     "start_time": "2016-10-12T22:21:30.601Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Taking a look at our top sales by zip code\n",
    "top_sales = df2.copy()\n",
    "top_sales.groupby('Zip Code')[['Sale (Dollars)', 'Volume Sold (Liters)']].\\\n",
    "sum().reset_index().sort_values(by='Sale (Dollars)', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.477207",
     "start_time": "2016-10-12T22:21:30.605Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_histograms(data, col):\n",
    "    sns.distplot(data[col]);\n",
    "    plt.title(col);\n",
    "    plt.xlabel(col);\n",
    "    plt.ylabel('Frequency');\n",
    "    plt.xticks(rotation=45);\n",
    "    plt.show();\n",
    "    print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.478036",
     "start_time": "2016-10-12T22:21:30.611Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mean sales and volume by zip codes\n",
    "agg_columns = ['Sale (Dollars)', 'Volume Sold (Liters)']\n",
    "zip_mean = df2.groupby('Zip Code')[agg_columns].mean().reset_index()\n",
    "zip_mean.columns = ['Zip Code', 'Mean Zip Sales', 'Mean Zip Volume']\n",
    "zip_mean_aggs = ['Mean Zip Sales', 'Mean Zip Volume']\n",
    "\n",
    "for i in zip_mean_aggs:\n",
    "    draw_histograms(zip_mean, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.478762",
     "start_time": "2016-10-12T22:21:30.615Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We'll take a look at our demographic data as well\n",
    "demo_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.479209",
     "start_time": "2016-10-12T22:21:30.619Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "demo_hist_cols = ['Per Capita Inc', 'Pop Below Poverty Level', '% P16+ in labor force']\n",
    "for i in demo_hist_cols:\n",
    "    draw_histograms(demo_data, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record your findings\n",
    "\n",
    "Be sure to write out anything observations from your exploratory analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of our market research, we are interested in total sales grouped by zip codes.  \n",
    "To get a fair idea of how each zip code does, we would want to remove the outlier stores (stores that do exceptionally well or poor) as these may not be a good indication of how an average store would fare in that zip code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mine the data\n",
    "Now you are ready to compute the variables you will use for your regression from the data. For example, you may want to\n",
    "compute total sales per store from Jan to March of 2015, mean price per bottle, etc. Refer to the readme for more ideas appropriate to your scenario.\n",
    "\n",
    "Pandas is your friend for this task. Take a look at the operations [here](http://pandas.pydata.org/pandas-docs/stable/groupby.html) for ideas on how to make the best use of pandas and feel free to search for blog and Stack Overflow posts to help you group data by certain variables and compute sums, means, etc. You may find it useful to create a new data frame to house this summary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.479700",
     "start_time": "2016-10-12T22:21:30.667Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.480118",
     "start_time": "2016-10-12T22:21:30.672Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Aggregate sales and volume by stores\n",
    "store_summary = df2.groupby('Store Number')[agg_columns].sum().reset_index()\n",
    "store_summary.columns = ['Store Number', 'Store Sales', 'Store Volume']\n",
    "store_aggs = ['Store Sales', 'Store Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.480525",
     "start_time": "2016-10-12T22:21:30.677Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in store_aggs:\n",
    "    draw_histograms(store_summary, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.481119",
     "start_time": "2016-10-12T22:21:30.681Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In terms of total sales, we will remove the outliers\n",
    "# Set at total sales > 100000\n",
    "store_summary = store_summary[store_summary['Store Sales'] <= 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.481953",
     "start_time": "2016-10-12T22:21:30.688Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in store_aggs:\n",
    "    draw_histograms(store_summary, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is still skewed but not as much as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.482693",
     "start_time": "2016-10-12T22:21:30.723Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now merge the summary with our cleaned dataset \n",
    "columns_required = ['Year', 'Month', 'Store Number', 'Zip Code', 'Area (sqkm)']\n",
    "df3 = df2.copy()[columns_required].merge(store_summary, how='left', on='Store Number').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.483394",
     "start_time": "2016-10-12T22:21:30.729Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.483846",
     "start_time": "2016-10-12T22:21:30.733Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Aggregate sales and volume by zip code\n",
    "zip_summary = df3.groupby('Zip Code')[store_aggs].sum().reset_index().dropna()\n",
    "zip_summary.columns = ['Zip Code', 'Zip Sales - Total', 'Zip Volume - Total']\n",
    "zip_aggs = ['Zip Sales - Total', 'Zip Volume - Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.484272",
     "start_time": "2016-10-12T22:21:30.737Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in zip_aggs:\n",
    "    draw_histograms(zip_summary, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't be dropping outliers at the zip level because we want to see the zips that are doing well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.484689",
     "start_time": "2016-10-12T22:21:30.769Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mean sales and volume by zip code\n",
    "zip_mean = df3.groupby('Zip Code')[store_aggs].mean().reset_index().dropna()\n",
    "zip_mean.columns = ['Zip Code', 'Zip Sales - Mean', 'Zip Volume - Mean']\n",
    "zip_mean_aggs = ['Zip Sales - Mean', 'Zip Volume - Mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.485099",
     "start_time": "2016-10-12T22:21:30.773Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in zip_mean_aggs:\n",
    "    draw_histograms(zip_mean, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.485510",
     "start_time": "2016-10-12T22:21:30.781Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = df3[columns_required].merge(zip_summary, how='left', on='Zip Code').drop_duplicates()\n",
    "df3 = df3.merge(zip_mean, how='left', on='Zip Code').drop_duplicates()\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.485923",
     "start_time": "2016-10-12T22:21:30.787Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add a column for price per liter based on mean sales and mean volumes\n",
    "df3['Dollar per liter'] = df3['Zip Sales - Total']/df3['Zip Volume - Total']\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.486341",
     "start_time": "2016-10-12T22:21:30.793Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add store count\n",
    "num_stores = df3[['Zip Code','Store Number']].drop_duplicates()\n",
    "num_stores = num_stores.groupby('Zip Code').count().reset_index()\n",
    "num_stores.columns = ['Zip Code', 'Store Count']\n",
    "df3 = df3.merge(num_stores, how='left', on='Zip Code')\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.486760",
     "start_time": "2016-10-12T22:21:30.796Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add stores per square kilometer\n",
    "df3['Stores per sqkm'] = df3['Store Count']/df3['Area (sqkm)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.487935",
     "start_time": "2016-10-12T22:21:30.800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scale the demo_data\n",
    "demo_data_scaled = demo_data.copy()\n",
    "cols_scale = demo_data_scaled.columns.values.tolist()[1:]\n",
    "scaler = StandardScaler().fit(demo_data_scaled[cols_scale])\n",
    "scaled_values = scaler.transform(demo_data_scaled[cols_scale])\n",
    "\n",
    "for i in range(len(cols_scale)):\n",
    "    demo_data_scaled[cols_scale[i]] = [x[i] for x in scaled_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.490037",
     "start_time": "2016-10-12T22:21:30.806Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rearranging our df so that month and year are the last 2 columns\n",
    "df3_columns = df3.columns.values.tolist()\n",
    "df3_columns = df3_columns[2:]\n",
    "df3_columns.extend(['Month', 'Year'])\n",
    "df3 = df3[df3_columns]\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.490655",
     "start_time": "2016-10-12T22:21:30.815Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_df = df3.merge(demo_data_scaled, how='left', left_on='Zip Code', right_on='Area').drop('Area', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.491100",
     "start_time": "2016-10-12T22:21:30.822Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refine the data\n",
    "Look for any statistical relationships, correlations, or other relevant properties of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.491531",
     "start_time": "2016-10-12T22:21:30.835Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,10));\n",
    "sns.heatmap(model_df.corr()[['Zip Sales - Total']].iloc[10:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.492237",
     "start_time": "2016-10-12T22:21:30.839Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,10));\n",
    "sns.heatmap(model_df.corr()[['Zip Volume - Total']].iloc[10:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your models\n",
    "\n",
    "Using scikit-learn or statsmodels, build the necessary models for your scenario. Evaluate model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.492956",
     "start_time": "2016-10-12T22:21:30.857Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = model_df.columns.values.tolist()\n",
    "print features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.493415",
     "start_time": "2016-10-12T22:21:30.861Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_features = ['Store Number', 'Zip Code', 'Area (sqkm)',\\\n",
    "                 'Zip Sales - Total', 'Zip Volume - Total', 'Zip Sales - Mean', 'Zip Volume - Mean',\\\n",
    "                 'Dollar per liter', 'Store Count', 'Stores per sqkm', 'Month']\n",
    "for i in drop_features:\n",
    "    features.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.495412",
     "start_time": "2016-10-12T22:21:30.865Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_df.dropna(inplace=True)\n",
    "X = model_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.496971",
     "start_time": "2016-10-12T22:21:30.870Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_sales = model_df['Zip Sales - Total']\n",
    "ridge = linear_model.RidgeCV(cv=5)\n",
    "model_sales = ridge.fit(X,y_sales)\n",
    "print 'r-squared: {}'.format(model_sales.score(X,y_sales))\n",
    "print 'alpha applied: {}'.format(model_sales.alpha_)\n",
    "\n",
    "feature_imp = pd.DataFrame([features, model_sales.coef_.tolist()], index=['feature', 'coef']).T\n",
    "feature_imp['coef'] = feature_imp['coef'].astype(float)\n",
    "feature_imp = feature_imp.sort_values(by='coef', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.498272",
     "start_time": "2016-10-12T22:21:30.874Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_volume = model_df['Zip Volume - Total']\n",
    "ridge2 = linear_model.RidgeCV(cv=5)\n",
    "model_volume = ridge2.fit(X,y_dollar)\n",
    "print 'r-squared: {}'.format(model_volume.score(X,y_volume))\n",
    "print 'alpha applied: {}'.format(model_volume.alpha_)\n",
    "\n",
    "feature_imp_v = pd.DataFrame([features, model_volume.coef_.tolist()], index=['feature', 'coef']).T\n",
    "feature_imp_v['coef'] = feature_imp_v['coef'].astype(float)\n",
    "feature_imp_v = feature_imp_d.sort_values(by='coef', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot your results\n",
    "\n",
    "Again make sure that you record any valuable information. For example, in the tax scenario, did you find the sales from the first three months of the year to be a good predictor of the total sales for the year? Plot the predictions versus the true values and discuss the successes and limitations of your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.499409",
     "start_time": "2016-10-12T22:21:30.887Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_sales = model_sales.predict(X)\n",
    "fig, ax = plt.subplots(figsize=(8,8));\n",
    "plt.scatter(predicted_sales, y_sales);\n",
    "plt.plot([min(y_sales), max(y_sales)], [min(y_sales), max(y_sales)], '-');\n",
    "plt.title('Predicted and actual sales');\n",
    "plt.xlabel('Predicted sales');\n",
    "plt.ylabel('Actual sales');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.500348",
     "start_time": "2016-10-12T22:21:30.892Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_volume = model_volume.predict(X)\n",
    "fig, ax = plt.subplots(figsize=(8,8));\n",
    "plt.scatter(predicted_volume, y_volume);\n",
    "plt.plot([min(y_volume), max(y_volume)], [min(y_volume), max(y_volume)], '-');\n",
    "plt.title('Predicted and actual volume');\n",
    "plt.xlabel('Predicted volume');\n",
    "plt.ylabel('Actual volume');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Present the Results\n",
    "\n",
    "Present your conclusions and results. If you have more than one interesting model feel free to include more than one along with a discussion. Use your work in this notebook to prepare your write-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.501330",
     "start_time": "2016-10-12T22:21:30.910Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict sales for all zip codes\n",
    "predict_df = location_data.copy()\n",
    "predict_df['Year'] = 2016\n",
    "predict_df = predict_df.merge(demo_data_scaled, left_on='Zip Code', right_on='Area').drop('Area', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.502934",
     "start_time": "2016-10-12T22:21:30.914Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_predict = predict_df[features]\n",
    "all_sales = model_sales.predict(X_predict)\n",
    "all_volume = model_volume.predict(X_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.504108",
     "start_time": "2016-10-12T22:21:30.925Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_df['Predicted Total Sales'] = all_sales\n",
    "predict_df['Predicted Total Volume'] = all_volume\n",
    "predict_df['Predicted Dollar/liter'] = predict_df['Predicted Total Sales']/predict_df['Predicted Total Volume']\n",
    "\n",
    "predict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.504979",
     "start_time": "2016-10-12T22:21:30.929Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "present_columns = ['Zip Code', 'Predicted Total Sales', 'Predicted Dollar/liter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.505875",
     "start_time": "2016-10-12T22:21:30.933Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "present_df = predict_df[present_columns]\n",
    "present_df = present_df.merge(df3[['Zip Code', 'Store Count', 'Area (sqkm)', 'Stores per sqkm',\\\n",
    "                                   'Zip Sales - Total', 'Dollar per liter']],\\\n",
    "                              how='left', on='Zip Code').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:19:00.162095",
     "start_time": "2016-10-12T18:18:59.928166"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "present_df.to_csv('predicted-numbers-with-features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T18:21:33.507378",
     "start_time": "2016-10-12T22:21:30.973Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_10 = present_df.sort_values(by='Predicted Total Sales', ascending=False).head(10)\n",
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
