{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-15T18:29:04.610827",
     "start_time": "2016-10-15T18:28:50.459498"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################################################\n",
    "############### EDIT THESE CONSTANTS\n",
    "############### \n",
    "###############        EDIT THESE CONSTANTS\n",
    "\n",
    "MAX_RESULTS_PER_CITY = 10       ### DO NOT SET MORE THAN 1000\n",
    "URL_SEARCH_TERM = 'Data Scientist' ### DO NOT SET MORE THAN SINGLE SEARCH TERM (TITLE)\n",
    "CITY_SET = ['New York', 'Chicago', 'San Francisco', 'Austin', 'Atlanta', '', 'Boston', 'Seattle']\n",
    "PHANTOM_PATH = '/Applications/anaconda/anaconda/bin/phantomJS' ## bash% which phantomJS\n",
    "\n",
    "###############\n",
    "################################################################\n",
    "\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium import webdriver\n",
    "import datetime\n",
    "import urllib\n",
    "\n",
    "def extract_location_from_resultRow(result):\n",
    "    try:\n",
    "        location = (result.find(class_='location').text.strip())\n",
    "    except:\n",
    "        location = ''\n",
    "    return location\n",
    "\n",
    "def extract_company_from_resultRow(result):\n",
    "    try:\n",
    "        company = (result.find(class_='company').text.strip())\n",
    "    except:\n",
    "        company = ''\n",
    "    return company\n",
    "\n",
    "def extract_jkid_from_resultRow(result):\n",
    "    try:\n",
    "        row = (result.find(class_='jobtitle turnstileLink'))\n",
    "        jkid = result['data-jk']\n",
    "    except: \n",
    "        jkid = ''\n",
    "    return jkid\n",
    "\n",
    "def extract_title_from_resultRow(result):\n",
    "    try:\n",
    "        title = (result.find(class_='turnstileLink'))\n",
    "        title_text = title.text\n",
    "    except: \n",
    "        title_text = ''\n",
    "    return title_text\n",
    "\n",
    "def extract_salary_from_resultRow(result):\n",
    "    try:\n",
    "        salary = (result.find(class_='snip').find('nobr').text)\n",
    "    except:\n",
    "        salary = ''\n",
    "    salary_text = salary\n",
    "    return salary_text\n",
    "\n",
    "def extract_reviews_from_resultRow(result):\n",
    "    try:\n",
    "        reviews = (result.find(class_='slNoUnderline').text.strip().strip(' reviews').replace(',',''))\n",
    "    except: \n",
    "        reviews = ''\n",
    "    return reviews\n",
    "\n",
    "def extract_stars_from_resultRow(result):\n",
    "    try: \n",
    "        stars = (result.find(class_='rating')['style']).split(';background-position:')[1].split(':')[1].split('px')[0].strip()\n",
    "    except: \n",
    "        stars = ''\n",
    "    return stars\n",
    "\n",
    "def extract_date_from_resultRow(result):\n",
    "    try: \n",
    "        date = (result.find(class_='date').text.strip(' ago').strip())\n",
    "    except: \n",
    "        date = ''\n",
    "    return date\n",
    "\n",
    "dcap = dict(DesiredCapabilities.PHANTOMJS)\n",
    "dcap[\"phantomjs.page.settings.userAgent\"] = (\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.PhantomJS(executable_path=PHANTOM_PATH, desired_capabilities=dcap)\n",
    "driver.set_window_size(1024, 768) \n",
    "\n",
    "for city in CITY_SET:\n",
    "    job_dict = []\n",
    "    now = datetime.datetime.now()\n",
    "    for start in range(0, MAX_RESULTS_PER_CITY, 10):\n",
    "\n",
    "        URL = \"http://www.indeed.com/jobs?q=\"+urllib.quote(URL_SEARCH_TERM)+\"&l=\"+urllib.quote(city)+\"&start=\"+str(start)\n",
    "        driver.get(URL)\n",
    "        soup = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "\n",
    "        for i in soup.findAll(\"div\", {\"data-tn-component\" : \"organicJob\"}):\n",
    "\n",
    "            location = extract_location_from_resultRow(i)\n",
    "            company = extract_company_from_resultRow(i)\n",
    "            jkid = extract_jkid_from_resultRow(i)\n",
    "            title = extract_title_from_resultRow(i)\n",
    "            salary = extract_salary_from_resultRow(i)\n",
    "            reviews = extract_reviews_from_resultRow(i)\n",
    "            stars = extract_stars_from_resultRow(i)\n",
    "            post_date = extract_date_from_resultRow(i)\n",
    "\n",
    "            job_dict.append([location, company, jkid,title, salary, stars, reviews, post_date, now])\n",
    "            \n",
    "        job_df = pd.DataFrame(job_dict, columns=['location', 'company', 'jkid', 'title', 'salary', 'stars', 'reviews', 'post_date', 'pull_date'])       \n",
    "\n",
    "    job_df.to_csv('scrape'+city+'_'+str(MAX_RESULTS_PER_CITY)+'.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
